<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Advanced Token Analyzer</title>

<style>
:root {
    --bg-dark: #0f172a;
    --bg-card: #1e293b;
    --primary: #6366f1;
    --primary-hover: #4f46e5;
    --accent: #22d3ee;
    --text-main: #f1f5f9;
    --text-muted: #94a3b8;
    --success: #22c55e;
    --border: #334155;
}

* { box-sizing: border-box; }

body {
    margin: 0;
    font-family: "Segoe UI", system-ui, -apple-system, sans-serif;
    background: linear-gradient(135deg, #0f172a, #1e293b);
    color: var(--text-main);
    padding: 20px;
}

.container {
    max-width: 1000px;
    margin: auto;
}

.card {
    background: var(--bg-card);
    padding: 40px;
    border-radius: 16px;
    box-shadow: 0 15px 40px rgba(0,0,0,0.4);
    margin-bottom: 40px;
}

h1 {
    text-align: center;
    font-size: 2.2rem;
    font-weight: 700;
    background: linear-gradient(to right, var(--primary), var(--accent));
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

h2 {
    color: var(--accent);
    margin-top: 0;
}

.description {
    text-align: center;
    color: var(--text-muted);
    margin-bottom: 30px;
}

.input-group {
    display: flex;
    gap: 10px;
    margin-bottom: 25px;
}

textarea {
    flex: 1;
    padding: 15px;
    border-radius: 10px;
    border: 1px solid var(--border);
    background-color: #0f172a;
    color: var(--text-main);
    font-size: 16px;
    resize: none;
    min-height: 100px;
}

textarea:focus {
    outline: none;
    border-color: var(--primary);
    box-shadow: 0 0 0 2px rgba(99,102,241,0.3);
}

button {
    background-color: var(--primary);
    color: white;
    border: none;
    padding: 0 25px;
    border-radius: 10px;
    cursor: pointer;
    font-weight: 600;
    transition: all 0.2s ease;
}

button:hover {
    background-color: var(--primary-hover);
    transform: translateY(-2px);
}

.result-box {
    background: #0f172a;
    border: 1px solid var(--border);
    padding: 20px;
    border-radius: 10px;
    margin-bottom: 15px;
}

.token-container {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
    margin-top: 10px;
}

.token {
    background: var(--success);
    padding: 6px 10px;
    border-radius: 6px;
    font-size: 14px;
    font-weight: 500;
    transition: transform 0.15s ease, box-shadow 0.15s ease;
}

.token:hover {
    transform: scale(1.1);
    box-shadow: 0 4px 10px rgba(34,197,94,0.5);
}

.info-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
    gap: 20px;
}

.info-box {
    background: #0f172a;
    border: 1px solid var(--border);
    padding: 20px;
    border-radius: 12px;
}

.info-box h3 {
    margin-top: 0;
    color: var(--primary);
}

p {
    line-height: 1.6;
    color: var(--text-muted);
}
</style>
</head>

<body>

<div class="container">

<div class="card">
    <h1>Advanced Token Analyzer</h1>
    <p class="description">
        Explore how text is broken into tokens and how AI models interpret language.
    </p>

    <div class="input-group">
        <textarea id="input-box" placeholder="Type or paste your text here..."></textarea>
        <button onclick="analyzeText()">Analyze</button>
    </div>

    <div class="result-box">
        <h2>Token Results</h2>
        <p><strong>Estimated Tokens:</strong> <span id="estimated-tokens">0</span></p>
        <p><strong>Actual Tokens:</strong> <span id="actual-tokens">0</span></p>
        <div class="token-container" id="token-container"></div>
    </div>
</div>

<div class="card">
    <h2>What Are Tokens?</h2>
    <p>
        Tokens are small pieces of text that AI models use instead of whole sentences.
        A token can be a word, part of a word, punctuation, or even a single character.
        For example, the word <strong>"running"</strong> might be split into 
        <strong>"run"</strong> and <strong>"ning"</strong>.
    </p>
</div>

<div class="card">
    <h2>How Tokenization Works</h2>
    <div class="info-grid">
        <div class="info-box">
            <h3>Step 1: Text Input</h3>
            <p>
                The model receives raw text as characters.
            </p>
        </div>
        <div class="info-box">
            <h3>Step 2: Splitting</h3>
            <p>
                The text is split into smaller pieces based on patterns and vocabulary rules.
            </p>
        </div>
        <div class="info-box">
            <h3>Step 3: Numeric Encoding</h3>
            <p>
                Each token is converted into a number so the neural network can process it.
            </p>
        </div>
    </div>
</div>

<div class="card">
    <h2>Why Tokens Matter</h2>
    <p>
        AI models have token limits. The number of tokens determines:
    </p>
    <ul>
        <li>How much text the model can process at once</li>
        <li>Response length limits</li>
        <li>Computation cost</li>
        <li>Memory usage</li>
    </ul>
</div>

<div class="card">
    <h2>Attention & Understanding</h2>
    <p>
        Modern transformer models use an "attention mechanism" to determine which tokens
        are most important in context. Each token can "look at" other tokens in the sequence
        to understand relationships and meaning.
    </p>
</div>

<div class="card">
    <h2>Estimated vs Actual Tokens</h2>
    <p>
        Estimated tokens are often calculated using simple rules (like 1 token â‰ˆ 4 characters).
        Actual tokens depend on the specific tokenizer used by the model, which may split
        words differently based on vocabulary patterns.
    </p>
</div>

</div>

<script>
function analyzeText() {
    const text = document.getElementById("input-box").value.trim();
    const estimatedTokens = Math.ceil(text.length / 4);
    const words = text.split(/\s+/).filter(word => word.length > 0);

    document.getElementById("estimated-tokens").innerText = estimatedTokens;
    document.getElementById("actual-tokens").innerText = words.length;

    const container = document.getElementById("token-container");
    container.innerHTML = "";

    words.forEach(word => {
        const tokenEl = document.createElement("div");
        tokenEl.className = "token";
        tokenEl.innerText = word;
        container.appendChild(tokenEl);
    });
}
</script>

</body>
</html>
